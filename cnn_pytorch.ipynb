{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# İs Cuda Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path,num_img):\n",
    "    array = np.zeros([num_img,64*32])\n",
    "    i = 0\n",
    "    for image in os.listdir(path):\n",
    "        img_path = path + \"\\\\\" + image\n",
    "        if image.endswith(\".png\"):\n",
    "            img = Image.open(img_path, mode=\"r\")\n",
    "            data = np.asarray(img, dtype=\"uint8\")\n",
    "            data = data.flatten()\n",
    "            array[i,:] = data\n",
    "            i += 1\n",
    "    return array    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_path = r\"C:\\Users\\mustdo\\Desktop\\workspace\\Machine Learning\\deeplearning\\LSIFIR\\Classification\\Train\\neg\"\n",
    "train_pos_path = r\"C:\\Users\\mustdo\\Desktop\\workspace\\Machine Learning\\deeplearning\\LSIFIR\\Classification\\Train\\pos\"\n",
    "\n",
    "pos_nums = 10208\n",
    "neg_nums = 43390\n",
    "\n",
    "pos_train_array = read_images(train_pos_path,pos_nums)\n",
    "neg_train_array = read_images(train_neg_path,neg_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10208])\n",
      "torch.Size([43390])\n"
     ]
    }
   ],
   "source": [
    "x_pos_train_tensor = torch.from_numpy(pos_train_array) #pozitif resimleri numpy arrayden torch tensora çevirdik\n",
    "\n",
    "y_pos_train_tensor =torch.ones(pos_nums,dtype=torch.long) #pozitif resimler boyutu kadar 1 lerden oluşan bir tensor\n",
    "\n",
    "print(y_pos_train_tensor.size())\n",
    "\n",
    "x_neg_train_tensor = torch.from_numpy(neg_train_array) #negatif resimleri numpy arrayden torch tensora çevirdik\n",
    "\n",
    "y_neg_train_tensor =torch.zeros(neg_nums,dtype=torch.long) #negatif resimler boyutunda 0 lardan oluşan bir tensor\n",
    "\n",
    "print(y_neg_train_tensor.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([53598, 2048])\n",
      "torch.Size([53598])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.cat((x_neg_train_tensor,x_pos_train_tensor),0) #pozitif ve negatif train verilerini x_train adıyla birleştirdik\n",
    "y_train = torch.cat((y_neg_train_tensor,y_pos_train_tensor),0) #kendi oluşturduğumuz 1 ve 0 lardan oluşan tensorları y_train adıyla birleştirdik\n",
    "print(x_train.size())\n",
    "\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_path = r\"C:\\Users\\mustdo\\Desktop\\workspace\\Machine Learning\\deeplearning\\LSIFIR\\Classification\\Test\\neg\"\n",
    "test_pos_path = r\"C:\\Users\\mustdo\\Desktop\\workspace\\Machine Learning\\deeplearning\\LSIFIR\\Classification\\Test\\pos\"\n",
    "\n",
    "pos_test_nums = 5944\n",
    "neg_test_nums = 22050\n",
    "\n",
    "neg_test_array = read_images(test_neg_path,neg_test_nums)\n",
    "pos_test_array = read_images(test_pos_path,pos_test_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5944])\n",
      "torch.Size([22050])\n"
     ]
    }
   ],
   "source": [
    "x_pos_test_tensor = torch.from_numpy(pos_test_array) #poztif test verilerini numpy arrayden torch tensore çevirdik\n",
    "\n",
    "y_pos_test_tensor =torch.ones(pos_test_nums,dtype=torch.long) #pozitif test verileri için 1 lerden oluşan tensor\n",
    "\n",
    "print(y_pos_test_tensor.size())\n",
    "\n",
    "x_neg_test_tensor = torch.from_numpy(neg_test_array) #negatif test verilerini numpy arrayden torch tensore çevirdik\n",
    "    \n",
    "y_neg_test_tensor =torch.zeros(neg_test_nums,dtype=torch.long) #negatif test verileri için 0 lerden oluşan tensor\n",
    "\n",
    "print(y_neg_test_tensor.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27994, 2048])\n",
      "torch.Size([27994])\n"
     ]
    }
   ],
   "source": [
    "x_test = torch.cat((x_neg_test_tensor,x_pos_test_tensor),0) #pozitif ve negatif train verilerini x_test adıyla birleştirdik\n",
    "y_test = torch.cat((y_neg_test_tensor,y_pos_test_tensor),0) #kendi oluşturduğumuz 1 ve 0 lardan oluşan tensorları y_train adıyla birleştirdik\n",
    "print(x_test.size())\n",
    "\n",
    "print(y_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[12000,:].reshape(64,32),cmap=\"gray\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_classes = 2\n",
    "batch_size = 2 \n",
    "lr = 0.0001\n",
    "\n",
    "\n",
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net,self).__init__()\n",
    "        \n",
    "    \n",
    "        self.conv1 = nn.Conv2d(1,10,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(10,16,5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*13*5,520)\n",
    "        self.fc2 = nn.Linear(520,130)\n",
    "        self.fc3 = nn.Linear(130,num_classes)\n",
    "    def forward(self,x):\n",
    "        x = self.pool(f.relu(self.conv1(x)))\n",
    "        x = self.pool(f.relu(self.conv2(x)))\n",
    "        x = x.view(-1,16*13*5)\n",
    "        \n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = f.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "from torch.utils import data\n",
    "    \n",
    "train = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test = torch.utils.data.TensorDataset(x_test,y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "import torch.optim as optim \n",
    "optimizer = optim.SGD(nnet.parameters(), lr=lr, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuarcy :  93.30213617203687\n",
      "train accuarcy :  99.67536102093362\n",
      "test accuarcy :  94.28806172751304\n",
      "train accuarcy :  99.73693048248069\n",
      "test accuarcy :  92.88061727513039\n",
      "train accuarcy :  99.85447218179783\n",
      "test accuarcy :  93.49503465028221\n",
      "train accuarcy :  99.97387962237397\n",
      "test accuarcy :  93.19497035078946\n",
      "train accuarcy :  99.98693981118699\n",
      "Train is done\n",
      "processing time :  68.94741425116857\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "total_step = len(train_loader)\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "loss_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gpu = False\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(batch_size,1,64,32)\n",
    "        inputs = inputs.float()\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = nnet(inputs)\n",
    "        \n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images,labels = data\n",
    "            \n",
    "            images = images.view(batch_size,1,64,32)\n",
    "            images =images.float()\n",
    "            \n",
    "            outputs = nnet(images)\n",
    "            _,predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if (i + 1) % 2 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                              (correct / total) * 100))\n",
    "    acc1 = 100*correct/total\n",
    "    print(\"test accuarcy : \",acc1)\n",
    "    test_acc.append(acc1)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            images,labels = data\n",
    "            \n",
    "            images = images.view(batch_size,1,64,32)\n",
    "            images =images.float()\n",
    "            \n",
    "            outputs = nnet(images)\n",
    "            _,predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc2 = 100*correct/total\n",
    "    print(\"train accuarcy : \",acc2)\n",
    "    train_acc.append(acc2)\n",
    "\n",
    "    \n",
    "print(\"Train is done\")\n",
    "    \n",
    "finish = time.time()\n",
    "\n",
    "processing_time = (finish-start)/60\n",
    "print(\"processing time : \",processing_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
